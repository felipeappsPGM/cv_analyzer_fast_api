# ğŸ¤– Resume Analyzer API

Sistema inteligente para anÃ¡lise automatizada de currÃ­culos usando Large Language Models (LLM) e LangGraph.

![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)
![Python](https://img.shields.io/badge/python-3.11+-green.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104.1-009688.svg)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15+-336791.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#-visÃ£o-geral)
- [Funcionalidades](#-funcionalidades)
- [Arquitetura](#-arquitetura)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [ConfiguraÃ§Ã£o](#-configuraÃ§Ã£o)
- [Uso](#-uso)
- [API Documentation](#-api-documentation)
- [Desenvolvimento](#-desenvolvimento)
- [Deploy](#-deploy)
- [ContribuiÃ§Ã£o](#-contribuiÃ§Ã£o)
- [LicenÃ§a](#-licenÃ§a)

## ğŸ¯ VisÃ£o Geral

O Resume Analyzer Ã© uma plataforma completa que utiliza inteligÃªncia artificial para analisar currÃ­culos e determinar a compatibilidade entre candidatos e vagas de emprego. O sistema processa automaticamente documentos em diversos formatos (PDF, DOC, DOCX, TXT) e gera anÃ¡lises detalhadas com scores ponderados.

### ğŸ” Como Funciona

1. **Cadastro de Vagas**: Recrutadores registram vagas com requisitos especÃ­ficos
2. **Upload de CurrÃ­culos**: Candidatos fazem upload de seus currÃ­culos
3. **AnÃ¡lise Inteligente**: IA processa e analisa compatibilidade usando LLM
4. **Rankings**: Sistema gera rankings de candidatos por vaga
5. **RelatÃ³rios**: GeraÃ§Ã£o de relatÃ³rios detalhados em PDF

## âœ¨ Funcionalidades

### ğŸ‘¥ GestÃ£o de UsuÃ¡rios
- âœ… Sistema de autenticaÃ§Ã£o JWT
- âœ… MÃºltiplos tipos de usuÃ¡rio (admin, recruiter, candidate)
- âœ… Perfis profissionais completos
- âœ… HistÃ³rico de experiÃªncias e formaÃ§Ã£o

### ğŸ¢ GestÃ£o Empresarial
- âœ… Cadastro de empresas
- âœ… GestÃ£o de vagas por empresa
- âœ… Dashboard para recrutadores
- âœ… MÃ©tricas e analytics

### ğŸ’¼ Perfis Profissionais
- âœ… ExperiÃªncia profissional detalhada
- âœ… FormaÃ§Ã£o acadÃªmica
- âœ… Cursos e certificaÃ§Ãµes
- âœ… CÃ¡lculo automÃ¡tico de completude

### ğŸ” AnÃ¡lise Inteligente
- âœ… IntegraÃ§Ã£o com mÃºltiplos LLMs (OpenAI, Anthropic, Groq, Gemini)
- âœ… Workflow de anÃ¡lise com LangGraph
- âœ… Sistema de pontuaÃ§Ã£o ponderada
- âœ… IdentificaÃ§Ã£o de pontos fortes e fracos

### ğŸ“Š Sistema de PontuaÃ§Ã£o

| CritÃ©rio | Peso | DescriÃ§Ã£o |
|----------|------|-----------|
| **ExperiÃªncia Profissional** | 35% | RelevÃ¢ncia e tempo de experiÃªncia |
| **FormaÃ§Ã£o AcadÃªmica** | 30% | NÃ­vel e Ã¡rea de formaÃ§Ã£o |
| **Cursos Profissionalizantes** | 20% | CertificaÃ§Ãµes e especializaÃ§Ãµes |
| **Pontos Fortes** | +15% | CompetÃªncias destacadas |
| **Pontos Fracos** | -10% | Ãreas de melhoria |

**FÃ³rmula:**
```
Score Final = (ExperiÃªncia Ã— 0.35) + (FormaÃ§Ã£o Ã— 0.30) + (Cursos Ã— 0.20) + (Pontos Fortes Ã— 0.15) - (Pontos Fracos Ã— 0.10)
```

## ğŸ—ï¸ Arquitetura

### Stack TecnolÃ³gico

#### Backend
- **Framework**: FastAPI 0.104.1
- **Linguagem**: Python 3.11+
- **ORM**: SQLAlchemy (Async)
- **Banco de Dados**: PostgreSQL 15+
- **MigraÃ§Ãµes**: Alembic
- **Cache**: Redis
- **Message Queue**: RabbitMQ

#### IA e Machine Learning
- **LLM Providers**: OpenAI, Anthropic, Groq, Gemini
- **Workflow Engine**: LangGraph
- **Processamento de Texto**: NLTK, spaCy
- **AnÃ¡lise de Documentos**: PyPDF2, python-docx

#### Infraestrutura
- **ContainerizaÃ§Ã£o**: Docker & Docker Compose
- **Servidor Web**: Uvicorn/Gunicorn
- **Proxy Reverso**: Nginx
- **Monitoramento**: Prometheus, Grafana

### Diagramas de Arquitetura

```mermaid
graph TB
    subgraph "Frontend"
        UI[Web Interface]
        API_CLIENT[API Client]
    end
    
    subgraph "Backend"
        GATEWAY[API Gateway]
        AUTH[Authentication]
        SERVICES[Business Services]
        REPOS[Repositories]
    end
    
    subgraph "AI/ML"
        LLM[LLM Providers]
        LANGGRAPH[LangGraph]
        ANALYSIS[Analysis Engine]
    end
    
    subgraph "Data Layer"
        POSTGRES[(PostgreSQL)]
        REDIS[(Redis Cache)]
        RABBITMQ[RabbitMQ]
    end
    
    UI --> API_CLIENT
    API_CLIENT --> GATEWAY
    GATEWAY --> AUTH
    GATEWAY --> SERVICES
    SERVICES --> REPOS
    REPOS --> POSTGRES
    SERVICES --> REDIS
    SERVICES --> RABBITMQ
    SERVICES --> ANALYSIS
    ANALYSIS --> LANGGRAPH
    LANGGRAPH --> LLM
```

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.11+
- Docker & Docker Compose
- PostgreSQL 15+ (ou usar Docker)
- Redis (ou usar Docker)
- Git

### InstalaÃ§Ã£o RÃ¡pida

1. **Clone o repositÃ³rio**:
   ```bash
   git clone https://github.com/seu-usuario/resume-analyzer-api.git
   cd resume-analyzer-api
   ```

2. **Execute o script de setup**:
   ```bash
   chmod +x setup.sh
   ./setup.sh
   ```

3. **Configure as variÃ¡veis de ambiente**:
   ```bash
   cp .env.example .env
   # Edite o arquivo .env com suas configuraÃ§Ãµes
   ```

4. **Inicie os serviÃ§os**:
   ```bash
   docker-compose up -d
   ```

### InstalaÃ§Ã£o Manual

<details>
<summary>Clique para ver instalaÃ§Ã£o manual</summary>

1. **Criar ambiente virtual**:
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate  # Linux/Mac
   .venv\Scripts\activate     # Windows
   ```

2. **Instalar dependÃªncias**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Configurar banco de dados**:
   ```bash
   # Inicie PostgreSQL via Docker
   docker run -d --name postgres \
     -e POSTGRES_DB=resume_analyzer \
     -e POSTGRES_USER=resume_user \
     -e POSTGRES_PASSWORD=resume_password \
     -p 5432:5432 postgres:15-alpine
   ```

4. **Executar migraÃ§Ãµes**:
   ```bash
   alembic upgrade head
   ```

5. **Iniciar aplicaÃ§Ã£o**:
   ```bash
   uvicorn app.main:app --reload
   ```

</details>

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente Essenciais

```env
# Database
DATABASE_URL=postgresql+asyncpg://user:pass@localhost:5432/resume_analyzer

# Security
SECRET_KEY=your-super-secret-key-minimum-64-characters
ALGORITHM=HS256

# LLM APIs
OPENAI_API_KEY=sk-your-openai-key
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key
GROQ_API_KEY=gsk_your-groq-key
GEMINI_API_KEY=your-gemini-key

# Cache & Queue
REDIS_URL=redis://localhost:6379/0
RABBITMQ_URL=amqp://user:pass@localhost:5672/
```

### ConfiguraÃ§Ã£o de LLM

O sistema suporta mÃºltiplos provedores de LLM:

| Provedor | Modelo PadrÃ£o | ConfiguraÃ§Ã£o |
|----------|---------------|--------------|
| **OpenAI** | gpt-4-1106-preview | `OPENAI_API_KEY` |
| **Anthropic** | claude-3-sonnet | `ANTHROPIC_API_KEY` |
| **Groq** | mixtral-8x7b-32768 | `GROQ_API_KEY` |
| **Gemini** | gemini-pro | `GEMINI_API_KEY` |

## ğŸ“– Uso

### Comandos de ManutenÃ§Ã£o

O sistema inclui um script de manutenÃ§Ã£o completo:

```bash
# Setup inicial do banco
python scripts/maintenance.py db-setup

# Criar usuÃ¡rio administrador
python scripts/maintenance.py user-create

# Backup do banco
python scripts/maintenance.py db-backup

# Health check completo
python scripts/maintenance.py health-check

# Limpeza de arquivos antigos
python scripts/maintenance.py cleanup --days 30

# Popular com dados de exemplo
python scripts/maintenance.py seed-data
```

### Exemplos de Uso da API

#### Criar UsuÃ¡rio
```bash
curl -X POST "http://localhost:8000/api/v1/users/" \
  -H "Content-Type: application/json" \
  -d '{
    "user_name": "JoÃ£o Silva",
    "user_email": "joao@email.com",
    "password": "MinhaSenh@123",
    "user_type": "candidate"
  }'
```

#### Upload de CurrÃ­culo
```bash
curl -X POST "http://localhost:8000/api/v1/curriculum/" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -F "file=@curriculo.pdf"
```

#### Criar Vaga
```bash
curl -X POST "http://localhost:8000/api/v1/jobs/" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "job_name": "Desenvolvedor Python SÃªnior",
    "activities": "Desenvolvimento de APIs em Python",
    "pre_requisites": "5+ anos Python, Django, PostgreSQL",
    "company_id": "uuid-da-empresa"
  }'
```

## ğŸ“š API Documentation

### Endpoints Principais

| Grupo | Endpoint | DescriÃ§Ã£o |
|-------|----------|-----------|
| **Auth** | `POST /api/v1/auth/login` | AutenticaÃ§Ã£o |
| **Users** | `GET /api/v1/users/` | Listar usuÃ¡rios |
| **Jobs** | `GET /api/v1/jobs/` | Listar vagas |
| **Applications** | `POST /api/v1/applications/` | Candidatar-se |
| **Analysis** | `GET /api/v1/analysis/{id}` | Resultado da anÃ¡lise |

### DocumentaÃ§Ã£o Interativa

Acesse a documentaÃ§Ã£o interativa:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### CÃ³digos de Status

| CÃ³digo | DescriÃ§Ã£o |
|--------|-----------|
| `200` | Sucesso |
| `201` | Criado com sucesso |
| `400` | Erro de validaÃ§Ã£o |
| `401` | NÃ£o autenticado |
| `403` | Sem permissÃ£o |
| `404` | NÃ£o encontrado |
| `422` | Erro de validaÃ§Ã£o Pydantic |
| `500` | Erro interno |

## ğŸ”§ Desenvolvimento

### ConfiguraÃ§Ã£o do Ambiente de Desenvolvimento

1. **Instalar dependÃªncias de desenvolvimento**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Configurar pre-commit hooks**:
   ```bash
   pre-commit install
   ```

3. **Executar testes**:
   ```bash
   pytest
   pytest --cov=app  # Com coverage
   ```

4. **Formatar cÃ³digo**:
   ```bash
   black .
   isort .
   flake8 .
   ```

### Estrutura do Projeto

```
resume-analyzer-api/
â”œâ”€â”€ app/                          # CÃ³digo da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ api/                      # Endpoints da API
â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚       â”œâ”€â”€ endpoints/        # Rotas especÃ­ficas
â”‚   â”‚       â””â”€â”€ router.py
â”‚   â”œâ”€â”€ config/                   # ConfiguraÃ§Ãµes
â”‚   â”‚   â”œâ”€â”€ database.py
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â”œâ”€â”€ core/                     # NÃºcleo da aplicaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ exceptions.py
â”‚   â”‚   â””â”€â”€ security.py
â”‚   â”œâ”€â”€ database/                 # Modelos do banco
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”œâ”€â”€ repositories/             # Camada de dados
â”‚   â”œâ”€â”€ schemas/                  # Pydantic schemas
â”‚   â”œâ”€â”€ services/                 # LÃ³gica de negÃ³cio
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ migrations/                   # MigraÃ§Ãµes Alembic
â”œâ”€â”€ scripts/                      # Scripts de utilidade
â”œâ”€â”€ tests/                        # Testes
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### Workflow de Desenvolvimento

1. **Criar branch para feature**:
   ```bash
   git checkout -b feature/nova-funcionalidade
   ```

2. **Desenvolver e testar**:
   ```bash
   # Fazer alteraÃ§Ãµes
   pytest  # Executar testes
   black . # Formatar cÃ³digo
   ```

3. **Commit e push**:
   ```bash
   git add .
   git commit -m "feat: adicionar nova funcionalidade"
   git push origin feature/nova-funcionalidade
   ```

4. **Criar Pull Request**

### Executando Testes

```bash
# Todos os testes
pytest

# Testes especÃ­ficos
pytest tests/test_services/

# Com coverage
pytest --cov=app --cov-report=html

# Testes de integraÃ§Ã£o
pytest tests/integration/

# Testes em paralelo
pytest -n auto
```

## ğŸš¢ Deploy

### Deploy Local (Docker)

```bash
# Build e start
docker-compose up -d

# Verificar status
docker-compose ps

# Ver logs
docker-compose logs -f api
```

### Deploy em ProduÃ§Ã£o

<details>
<summary>Deploy com Docker Swarm</summary>

```bash
# Inicializar swarm
docker swarm init

# Deploy stack
docker stack deploy -c docker-compose.prod.yml resume-analyzer

# Verificar serviÃ§os
docker service ls
```

</details>

<details>
<summary>Deploy no Kubernetes</summary>

```bash
# Aplicar manifests
kubectl apply -f k8s/

# Verificar status
kubectl get pods -n resume-analyzer

# Acompanhar logs
kubectl logs -f deployment/resume-analyzer-api
```

</details>

### VariÃ¡veis de Ambiente ProduÃ§Ã£o

```env
# ProduÃ§Ã£o
DEBUG=false
ENVIRONMENT=production
LOG_LEVEL=WARNING

# Security
SECRET_KEY=production-secret-key-64-characters-minimum
ALLOWED_HOSTS=https://yourdomain.com

# Database
DATABASE_URL=postgresql+asyncpg://user:pass@db:5432/resume_analyzer

# Monitoring
SENTRY_DSN=https://your-sentry-dsn@sentry.io/project
```

## ğŸ§ª Testes

### Tipos de Teste

- **Unit Tests**: Testam componentes isolados
- **Integration Tests**: Testam integraÃ§Ã£o entre componentes
- **E2E Tests**: Testam fluxos completos
- **Performance Tests**: Testam performance da API

### Executar SuÃ­te Completa

```bash
# Testes unitÃ¡rios
pytest tests/unit/

# Testes de integraÃ§Ã£o
pytest tests/integration/

# Testes E2E
pytest tests/e2e/

# Coverage report
pytest --cov=app --cov-report=html
open htmlcov/index.html
```

## ğŸ“Š Monitoramento

### MÃ©tricas DisponÃ­veis

- **API Metrics**: LatÃªncia, throughput, erro rate
- **Database Metrics**: ConexÃµes, queries, performance
- **LLM Metrics**: Uso de tokens, custos, latÃªncia
- **Business Metrics**: AnÃ¡lises processadas, usuÃ¡rios ativos

### Health Checks

```bash
# Health check da API
curl http://localhost:8000/api/v1/health

# Health check completo
python scripts/maintenance.py health-check
```

### Logs

```bash
# Ver logs da aplicaÃ§Ã£o
tail -f logs/app.log

# Logs do Docker
docker-compose logs -f api

# Logs estruturados
grep "level=ERROR" logs/app.log | jq .
```

## ğŸ¤ ContribuiÃ§Ã£o

### Como Contribuir

1. **Fork o projeto**
2. **Criar branch para feature** (`git checkout -b feature/AmazingFeature`)
3. **Commit suas mudanÃ§as** (`git commit -m 'Add some AmazingFeature'`)
4. **Push para a branch** (`git push origin feature/AmazingFeature`)
5. **Abrir Pull Request**

### Diretrizes

- Seguir o padrÃ£o de cÃ³digo (Black, isort, flake8)
- Escrever testes para novas funcionalidades
- Documentar mudanÃ§as no cÃ³digo
- Atualizar documentaÃ§Ã£o se necessÃ¡rio

### Reportar Issues

Use as [GitHub Issues](https://github.com/seu-usuario/resume-analyzer-api/issues) para:

- ğŸ› Reportar bugs
- ğŸ’¡ Sugerir features
- ğŸ“ Melhorias na documentaÃ§Ã£o
- â“ Fazer perguntas

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ†˜ Suporte

- **Email**: support@resume-analyzer.com
- **Discord**: [Resume Analyzer Community](https://discord.gg/resume-analyzer)
- **GitHub Issues**: [Issues](https://github.com/seu-usuario/resume-analyzer-api/issues)
- **Documentation**: [Wiki](https://github.com/seu-usuario/resume-analyzer-api/wiki)

## ğŸ™ Agradecimentos

- [FastAPI](https://fastapi.tiangolo.com/) - Framework web moderno
- [SQLAlchemy](https://www.sqlalchemy.org/) - ORM Python
- [LangChain](https://langchain.com/) - Framework para LLM
- [PostgreSQL](https://www.postgresql.org/) - Banco de dados
- [Docker](https://www.docker.com/) - ContainerizaÃ§Ã£o

---

**Status do Projeto**: ğŸŸ¢ Em Desenvolvimento Ativo

**Ãšltima AtualizaÃ§Ã£o**: Janeiro 2025

**VersÃ£o**: 1.0.0